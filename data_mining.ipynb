{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "This file collects the data used for machine learning predictions by web scrapping [sports-reference.com](sports-reference.com).\n",
    "\n",
    "*Note:  Web Scrapping [sports-reference](sports-reference.com) should be done carefully so as not to overload their servers.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattcallicott/opt/anaconda3/envs/playground/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Web Scrapping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_data`:  gets the offensive and defensive game-average statistics for each `team` and `year` combination. \n",
    " \n",
    "Returns two Pandas DataFrames in the form (offense, defense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(team_name: str, year: int) -> (pd.DataFrame, pd.DataFrame):\n",
    "\turl = f'https://www.sports-reference.com/cfb/schools/{team_name}/{year}.html'\n",
    "\n",
    "\tpage = requests.get(url)\n",
    "\tsoup = BeautifulSoup(page.text, 'html.parser')\n",
    "\t\n",
    "\tteam_table = soup.find('table', id='team')\n",
    "\n",
    "\trows = team_table.find_all('tr')\n",
    "\n",
    "\tteam_offense = [team_name] + [x.text for x in rows[2].find_all('td')]\n",
    "\tteam_defense = [team_name] + [x.text for x in rows[3].find_all('td')]\n",
    "\n",
    "\tcolumns = ['team', 'g', 'pass_cmp', 'pass_att', 'pass_pct', 'pass_yds', 'pass_td', 'rush_att', 'rush_yds', 'rush_avg', 'rush_td', 'total_plays', 'total_yds', 'total_avg', 'remove_1', 'remove_2', 'remove_3', 'remove_4', 'penalty_num', 'penalty_yds', 'fumbles', 'interceptions', 'turnovers']\n",
    "\n",
    "\tteam_offense_df = pd.DataFrame({i: [x] for i, x in zip(columns, team_offense)}).drop(columns=['g'])\n",
    "\tteam_defense_df = pd.DataFrame({i: [x] for i, x in zip(columns, team_defense)}).drop(columns=['g'])\n",
    "\n",
    "\treturn team_offense_df, team_defense_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`format_team_name`:  formats a raw team name by converting the name to lowercase and replacing spaces with dashes. \n",
    " \n",
    "Returns a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_team_name(raw_team_name: str) -> str:\n",
    "\tteam_name = raw_team_name\n",
    "\tif '\\xa0' in team_name:\n",
    "\t\tteam_name = raw_team_name.split('\\xa0')[1]\n",
    "\tteam_name = team_name.replace(' ', '-')\n",
    "\tteam_name = team_name.lower()\n",
    "\n",
    "\treturn team_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_schedule`:  gets the schedule for each `team` and `year` combination. \n",
    " \n",
    "Returns Pandas DataFrame that contains the home team, away team, outcome, and points for and against for each game `team` played during `year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schedule(team_name: str, year: int) -> pd.DataFrame:\n",
    "\n",
    "\tpage = requests.get(f'https://www.sports-reference.com/cfb/schools/{team_name}/{year}-schedule.html')\n",
    "\tsoup = BeautifulSoup(page.text, 'html.parser')\n",
    "\ttable = soup.find('table', id='schedule')\n",
    "\n",
    "\tdata = {\n",
    "\t\t'home_team': [],\n",
    "\t\t'away_team': [],\n",
    "\t\t'outcome': [],\n",
    "\t\t'pts_for': [],\n",
    "\t\t'pts_against': []\n",
    "\t}\n",
    "\n",
    "\n",
    "\tfor table_row in table.find_all('tr'):\n",
    "\t\trow_data = [x.text for x in table_row.find_all('td')]\n",
    "\n",
    "\t\tif row_data:\n",
    "\t\t\tif row_data[9]:\n",
    "\n",
    "\n",
    "\n",
    "\t\t\t\thome_team = format_team_name(row_data[3])\n",
    "\t\t\t\taway_team = format_team_name(row_data[5])\n",
    "\t\t\t\tloc = row_data[4]\n",
    "\t\t\t\toutcome = row_data[7]\n",
    "\t\t\t\tpts_for_obs = row_data[8]\n",
    "\t\t\t\tpts_against_obs = row_data[9]\n",
    "\n",
    "\t\t\t\tif loc == '@':\n",
    "\t\t\t\t\thome_team, away_team = away_team, home_team\n",
    "\t\t\t\t\toutcome = 'W' if outcome == 'L' else 'L'\n",
    "\t\t\t\t\n",
    "\t\t\t\tif outcome == 'W':\n",
    "\t\t\t\t\tpts_for, pts_aginst = max(pts_for_obs, pts_against_obs), min(pts_for_obs, pts_against_obs)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tpts_aginst, pts_for = max(pts_for_obs, pts_against_obs), min(pts_for_obs, pts_against_obs)\n",
    "\n",
    "\t\t\t\tdata['home_team'].append(home_team)\n",
    "\t\t\t\tdata['away_team'].append(away_team)\n",
    "\t\t\t\tdata['outcome'].append(outcome)\n",
    "\t\t\t\tdata['pts_for'].append(pts_for)\n",
    "\t\t\t\tdata['pts_against'].append(pts_aginst)\n",
    "\n",
    "\treturn pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an updated list of each team sports-reference.com has by using the `year`'s standings.  \n",
    "\n",
    "Intializes `team_names` which contains every team name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(f'https://www.sports-reference.com/cfb/years/{year}-standings.html')\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "schools_table = soup.find('table', id='standings')\n",
    "\n",
    "team_names = []\n",
    "\n",
    "for table_row in schools_table.find_all('tr')[2:]:\n",
    "\ttry:\n",
    "\t\tteam_name = table_row.find_all('a')[0].get('href').split('/')[-2]\n",
    "\t\tteam_names.append(team_name)\n",
    "\texcept IndexError:\n",
    "\t\tcontinue\n",
    "\texcept TypeError:\n",
    "\t\tcontinue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterates over `team_names` and aggregates the offensive and defensive statistics for each team in `offense_df` and `defense_df`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  old-dominion\n",
      "Error:  connecticut\n"
     ]
    }
   ],
   "source": [
    "offense_df = None\n",
    "defense_df = None\n",
    "\n",
    "for team_name in team_names:\n",
    "\ttry:\n",
    "\t\tteam_offense_df, team_defense_df = get_data(team_name, year)\n",
    "\t\t\n",
    "\t\tif offense_df is None or defense_df is None:\n",
    "\t\t\toffense_df = team_offense_df\n",
    "\t\t\tdefense_df = team_defense_df\n",
    "\t\telse:\n",
    "\t\t\toffense_df = pd.concat((offense_df, team_offense_df))\n",
    "\t\t\tdefense_df = pd.concat((defense_df, team_defense_df))\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error:  {team_name}\")\n",
    "\ttime.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformats `offense_df` and `defense_df` and writes each to output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "offense_df = offense_df.reset_index().drop(columns=['index'])\n",
    "defense_df = defense_df.reset_index().drop(columns=['index'])\n",
    "\n",
    "offense_df.to_csv('data/offense.csv', index=False)\n",
    "defense_df.to_csv('data/defense.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets the entire college football schedule for `year` by iterating over `team_names`.  \n",
    "\n",
    "Saves schedule as `schedule_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_df = None\n",
    "\n",
    "for team_name in team_names:\n",
    "\ttry:\n",
    "\t\tteam_schedule_df = get_schedule(team_name, year)\n",
    "\n",
    "\t\tif schedule_df is None:\n",
    "\t\t\tschedule_df = team_schedule_df\n",
    "\t\telse:\n",
    "\t\t\tschedule_df = pd.concat((schedule_df, team_schedule_df))\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error:  {team_name}\")\n",
    "\ttime.sleep(1)\n",
    "\n",
    "schedule_df = schedule_df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_df.to_csv(f'data/schedule_{year}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the `X` feature space by iterating over `schedule_df` and joining the relevant `offense_df` and `defense_df` for both home and away teams. Only grabs relevant columns. \n",
    "\n",
    "Aggregates statistics by game into `game_df`, which is appended to `X` to form a complete repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = None\n",
    "\n",
    "\n",
    "for idx, row in schedule_df.iterrows():\n",
    "\n",
    "\n",
    "\thome_team = row['home_team']\n",
    "\taway_team = row['away_team']\n",
    "\twin_loss_ratio = row['win_loss_ratio']\n",
    "\n",
    "\thome_offense = offense_df.query('team == @home_team')[[x for x in offense_df.columns if 'remove' not in x and x != 'team']].astype('float').reset_index(drop=True)\n",
    "\thome_defense = defense_df.query('team == @home_team')[[x for x in offense_df.columns if 'remove' not in x and x != 'team']].astype('float').reset_index(drop=True)\n",
    "\taway_offense = offense_df.query('team == @away_team')[[x for x in offense_df.columns if 'remove' not in x and x != 'team']].astype('float').reset_index(drop=True)\n",
    "\taway_defense = defense_df.query('team == @away_team')[[x for x in offense_df.columns if 'remove' not in x and x != 'team']].astype('float').reset_index(drop=True)\n",
    "\n",
    "\t# home_advantage = pd.concat((home_offense, away_defense)).diff(1).dropna().reset_index(drop=True)\n",
    "\t# away_advantage = pd.concat((away_offense, home_defense)).diff(1).dropna().reset_index(drop=True)\n",
    "\t\n",
    "\t# game_df = pd.merge(left=home_advantage, right=away_advantage, left_index=True, right_index=True, suffixes=('_home', '_away'))\n",
    "\n",
    "\tgame_df = pd.merge(home_offense, home_defense, left_index=True, right_index=True, suffixes=('_home_off', '_home_def'))\n",
    "\tgame_df = pd.merge(home_offense, home_defense, left_index=True, right_index=True, suffixes=('_home_off', '_home_def'))\n",
    "\tgame_df = pd.merge(game_df, away_offense, left_index=True, right_index=True, suffixes=('', '_away_off'))\n",
    "\tgame_df = pd.merge(game_df, away_defense, left_index=True, right_index=True, suffixes=('', '_away_off'))\n",
    "\n",
    "\tif game_df.shape[0] != 0:\n",
    "\t\tgame_df['index'] = [idx]\n",
    "\t\tif X is None:\n",
    "\t\t\tX = game_df\n",
    "\t\telse:\n",
    "\t\t\tX = pd.concat((X, game_df))\n",
    "\n",
    "X = X.set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines `X` with relevant outcome variables. \n",
    "\n",
    "Separates data into final `X` and `y` DataFrames. Writes each to output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(left=X, right=schedule_df[['pts_for', 'pts_against', 'outcome']], left_index=True, right_index=True)\n",
    "\n",
    "X = data.drop(columns=['pts_for', 'pts_against', 'outcome'])\n",
    "y = data['outcome'].apply(lambda x: 1 if x == 'W' else 0)\n",
    "\n",
    "#X.to_csv(f'data/X_{year}.csv', index=False)\n",
    "#y.to_csv(f'data/y_{year}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('playground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3b47c5f1c35f5ce04a4d0eaadcc6048a4991d4555138ee298068969dd3a7b16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
